{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# A Corpus-Based Acoustic Analysis of Monophthong Vowels among Chinese Learners and Native Speakers of English - Part 3\n",
                "\n",
                "Martin Schweinberger (`r format(Sys.time(), '%Y-%m-%d')`)\n",
                "\n",
                "\n",
                "## Introduction\n",
                "\n",
                "## Preparation\n",
                "\n",
                "load packages\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(tidyverse)\n",
                "library(here)\n",
                "library(adehabitatHR)\n",
                "library(lme4)\n",
                "library(sjPlot)\n",
                "library(report)\n",
                "library(flextable)\n",
                "library(cowplot)      \n",
                "library(randomForest) \n",
                "library(rms)    \n",
                "library(caret) \n",
                "library(Hmisc) \n",
                "library(quanteda)  \n",
                "#library(glmulti) \n",
                "library(partykit)   \n",
                "library(ggparty)\n",
                "library(hunspell)\n",
                "library(janitor)\n",
                "# set options\n",
                "options(stringsAsFactors = F)                           \n",
                "options(scipen = 999) \n",
                "options(max.print=10000)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load data\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load .rda data\n",
                "cdat  <- base::readRDS(file = here::here(\"data\", \"cleandat.rda\")) %>%\n",
                "  dplyr::ungroup()\n",
                "# inspect\n",
                "str(cdat); head(cdat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Reduce data\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bdat <- cdat %>%\n",
                "  dplyr::mutate(label = stringr::str_remove_all(label, \":\"),\n",
                "                gender = ifelse(gender == \"f\", \"female\", gender),\n",
                "                gender = ifelse(gender == \"m\", \"male\", gender),\n",
                "                tvariety = ifelse(tvariety == \"us\", \"AmE\", tvariety),\n",
                "                tvariety = ifelse(tvariety == \"gb\", \"BrE\", tvariety)) %>%\n",
                "#  dplyr::filter(label != \"A\",\n",
                "#                label != \"O\") %>%\n",
                "  droplevels(.)  %>%\n",
                "  dplyr::rename(Vowel = label,\n",
                "                Word = word,\n",
                "                TargetVariety = tvariety,\n",
                "                Gender = gender,\n",
                "                Duration = duration,\n",
                "                Proficiency = prof,\n",
                "                Speaker = speaker) %>%\n",
                "  # clean word\n",
                "  dplyr::mutate(Word = str_remove_all(Word, \"\\\\W\")) %>%\n",
                "  dplyr::filter(hunspell_check(Word) == T) %>%\n",
                "  # remove \"shits\"\n",
                "  dplyr::filter(Word != \"shits\",\n",
                "                Word != \"stat\",\n",
                "                Word != \"whats\")\n",
                "# inspect\n",
                "head(bdat); names(table(bdat$Word))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Check frequency of words\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create a vector of words\n",
                "words <- names(table(bdat$Word))\n",
                "# load ace files\n",
                "afiles <- list.files(here::here(\"ACE\"), pattern = \".TXT\", recursive = T, full.names = T) \n",
                "bfiles <- list.files(here::here(\"BROWN\"), pattern = \".TXT\", recursive = T, full.names = T) \n",
                "lfiles <- list.files(here::here(\"LOB\"), pattern = \".TXT\", recursive = T, full.names = T) \n",
                "cfiles <- c(afiles, bfiles, lfiles)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load the files by scanning the content\n",
                "controlc <- sapply(cfiles, function(x){\n",
                "  x <- scan(x, what = \"char\",  sep = \"\", quote = \"\",  quiet = T,  skipNul = T)\n",
                "  x <- paste0(x, sep = \" \", collapse = \" \")\n",
                "  x <- stringr::str_squish(x)\n",
                "})\n",
                "controlc <- paste0(controlc, collapse = \" \")\n",
                "# inspect\n",
                "str(controlc)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "extract word count of control corpus\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cleancontrolc <- controlc %>%\n",
                "  stringr::str_replace_all(\"<.*?>\", \" \") %>%\n",
                "  stringr::str_replace_all(\"[^[:alpha:] ]\", \" \") %>%\n",
                "  stringr::str_squish() %>%\n",
                "  quanteda::tokenize_fastestword() %>%\n",
                "  unlist() %>%\n",
                "  length()\n",
                "# inspect\n",
                "cleancontrolc\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "check how frequent the words are in the control corpus\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "freqs <- sapply(words, function(x){\n",
                "  x <- stringr::str_count(controlc, paste0(\"\\\\W\", x, \"\\\\W\", sep = \"\", collapse = \"\"))\n",
                "})\n",
                "# convert into data frame\n",
                "freqsdf <- data.frame(names(freqs), freqs, cleancontrolc) %>%\n",
                "  dplyr::rename(Word = 1,\n",
                "                all = 3) %>%\n",
                "  dplyr::mutate(Frequency = log(freqs/all*1000)) %>%\n",
                "  dplyr::select(-freqs, -all)\n",
                "# inspect\n",
                "head(freqsdf)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Annotate word class\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lexical <- c(\"bad\",  \"bed\", \"best\", \"big\", \"bit\", \"book\", \"books\", \"boost\", \"boots\", \"boss\", \"bought\", \"buds\", \"bus\", \"butts\", \"dad\", \"dead\", \"death\", \"debt\", \"debts\", \"desk\", \"dish\",  \"dust\", \"gap\", \"gas\",  \"good\",  \"guess\", \"head\", \"heads\",  \"hit\", \"hot\", \"key\", \"kid\", \"kids\", \"pass\", \"past\", \"pat\", \"path\", \"pub\", \"pubs\", \"push\", \"sad\", \"said\", \"sat\", \"says\", \"seat\", \"seats\", \"see\", \"seep\", \"sees\", \"set\", \"sets\",  \"shits\", \"shoes\", \"shop\", \"shops\", \"shut\", \"sit\", \"skip\",  \"speak\", \"spots\", \"stat\", \"step\", \"steps\", \"stop\", \"stops\", \"stud\", \"suit\", \"task\", \"tasks\", \"tea\", \"teeth\", \"test\", \"tests\", \"took\", \"top\", \"tough\", \"two\", \"wash\", \"ways\",  \"weak\", \"weed\", \"week\",  \"wish\",  \"wood\")\n",
                "bdat <- bdat %>%\n",
                "  dplyr::mutate(WordClass = ifelse(Word %in% lexical, \"lexical\", \"grammatical\"),\n",
                "                Word = as.vector(Word))\n",
                "bdat <- left_join(bdat, freqsdf, by = \"Word\")\n",
                "# inspect\n",
                "table(bdat$WordClass); head(bdat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Check durations\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bdat %>%\n",
                "  dplyr::mutate(Vowel = dplyr::case_when(Vowel == \"{\" ~ \"\\u00E6\",\n",
                "                                         Vowel == \"6\" ~ \"\\u0250\",\n",
                "                                         Vowel == \"e\" ~ \"\\u0065\",\n",
                "                                         Vowel == \"E\" ~ \"\\u025B\",\n",
                "                                         Vowel == \"i\" ~ \"\\u0069\",\n",
                "                                         Vowel == \"I\" ~ \"\\u026A\",\n",
                "                                         Vowel == \"Q\" ~ \"\\u0252\",\n",
                "                                         Vowel == \"u\" ~ \"\\u0075\",\n",
                "                                         Vowel == \"U\" ~ \"\\u028A\",\n",
                "                                         Vowel == \"V\" ~ \"\\u028C\",\n",
                "                                         TRUE ~ Vowel))  %>%\n",
                "  ggplot(aes(x = Vowel, y = Duration)) +\n",
                "  geom_boxplot()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Remove items with exaggerated duration\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nrow(bdat)\n",
                "bdat <- bdat  %>%\n",
                "  # remove rare words\n",
                "  dplyr::group_by(type, Word) %>%\n",
                "  dplyr::mutate(freq = n()) %>%\n",
                "#  dplyr::mutate(Word = ifelse(freq > 10, Word, \"other\")) %>%\n",
                "  dplyr::ungroup()\n",
                "# harmonize words\n",
                "nnwords <- bdat %>%\n",
                "  dplyr::filter(type == \"CHN\") %>%\n",
                "  dplyr::group_by(Word) %>%\n",
                "  dplyr::summarise(Freq = n()) %>%\n",
                "  dplyr::pull(Word)\n",
                "\n",
                "# remove rare vowels\n",
                "bdat <- bdat %>%\n",
                "  dplyr::group_by(Vowel) %>%\n",
                "  dplyr::mutate(fr = n()) %>%\n",
                "  dplyr::filter(fr > 100) %>%\n",
                "  dplyr::select(-fr) %>%\n",
                "  dplyr::ungroup()\n",
                "# inspect\n",
                "str(bdat); nrow(bdat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bdat %>%\n",
                "  dplyr::mutate(Vowel = dplyr::case_when(Vowel == \"{\" ~ \"\\u00E6\",\n",
                "                                         Vowel == \"6\" ~ \"\\u0250\",\n",
                "                                         Vowel == \"e\" ~ \"\\u0065\",\n",
                "                                         Vowel == \"E\" ~ \"\\u025B\",\n",
                "                                         Vowel == \"i\" ~ \"\\u0069\",\n",
                "                                         Vowel == \"I\" ~ \"\\u026A\",\n",
                "                                         Vowel == \"Q\" ~ \"\\u0252\",\n",
                "                                         Vowel == \"u\" ~ \"\\u0075\",\n",
                "                                         Vowel == \"U\" ~ \"\\u028A\",\n",
                "                                         Vowel == \"V\" ~ \"\\u028C\",\n",
                "                                         TRUE ~ Vowel))  %>%\n",
                "  ggplot(aes(x = Vowel, y = Duration)) +\n",
                "  geom_boxplot()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tb2 <- bdat %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Age = dplyr::case_when(Age < 30 ~ \"18-29\",\n",
                "                                       Age < 40 ~ \"30-39\",\n",
                "                                       Age < 50 ~ \"40-49\",\n",
                "                                       Age > 49 ~ \"50+\",\n",
                "                                       TRUE ~ \"unknown\")) %>%\n",
                "  dplyr::group_by(type, Gender, Age) %>%\n",
                "  dplyr::summarise(speakers = length(table(Speaker))) %>%\n",
                "  tidyr::spread(Age, speakers) %>%\n",
                "  dplyr::ungroup()  %>%\n",
                "  adorn_totals(\"row\")%>%\n",
                "  adorn_totals(\"col\")\n",
                "# save\n",
                "write.table(tb2, here::here(\"tables\", \"tb2_icame.txt\"), sep = \"\\t\")\n",
                "# inspect\n",
                "tb2\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bdat <- bdat %>%\n",
                "  dplyr::mutate(F1 = as.vector(scale(F1)),\n",
                "                F2 = as.vector(scale(F2)),\n",
                "                Duration = as.vector(scale(Duration)),\n",
                "                Age = as.vector(scale(Age)))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mixed-Model\n",
                "\n",
                "Prepare data\n",
                "\n",
                "Find frequent words (N > 5) that occur in both ENS and CHN data (WARNING: based on words determined to be shared in the ENS train, ENS test and CHN data for the MuPDARF)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "nswords <- c(\"bad\", \"be\", \"best\", \"big\", \"book\", \"books\", \"boss\", \"but\", \"did\", \"do\", \"due\", \"gas\", \"get\", \"gets\", \"good\", \"got\", \"guess\", \"had\", \"has\", \"he\", \"his\", \"keep\", \"kids\", \"other\", \"past\", \"pub\", \"put\", \"said\", \"see\", \"she\", \"sit\", \"step\", \"stop\", \"stud\", \"teeth\", \"that\", \"this\", \"too\", \"took\", \"tough\", \"two\", \"was\", \"we\", \"what\", \"who\", \"wish\", \"with\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "process data and make it ready for GLMM\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mdat <- bdat %>%\n",
                "  dplyr::filter(Vowel == \"i\"|Vowel == \"I\"|Vowel == \"u\"|Vowel == \"U\"|Vowel == \"E\"|Vowel == \"{\") %>%\n",
                "  dplyr::select(-Vowel, -TargetVariety, -edist, -barkF1, -barkF2, -lobF1, \n",
                "                -lobF2, -normF1, -normF2, -cF1, -cF2, -ED, -WordType, -freq, -file, -id, -fspeaker) %>%\n",
                "  dplyr::rename(Vowel = vowel) %>%\n",
                "  dplyr::mutate(Word = ifelse(Word %in% nswords, Word, \"other\")) %>%\n",
                "  dplyr::mutate_if(is.character, factor)\n",
                "  # inspect\n",
                "str(mdat)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Baseline model\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# set options\n",
                "options(contrasts  =c(\"contr.treatment\", \"contr.poly\"))\n",
                "mdat.dist <- datadist(mdat)\n",
                "options(datadist = \"mdat.dist\")\n",
                "# generate initial minimal regression model \n",
                "# baseline model glm\n",
                "ma = glmer(Duration ~ (1 | Word) + (1|Speaker), family = gaussian, data = mdat) \n",
                "# inspect results\n",
                "summary(ma)\n",
                "# inspect \n",
                "sjPlot::tab_model(ma)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Model fitting\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# wrapper function for linear mixed-models\n",
                "glmer.glmulti <- function(formula, data, random=\"\",...){\n",
                "  lmer(paste(deparse(formula),random),  data=data, ...)\n",
                "}\n",
                "# define formular\n",
                "form_glmulti = as.formula(paste(\"Duration ~  Vowel + type +  Gender + WordClass\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Extract best 5 models.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(glmulti)\n",
                "# multi selection for glmer\n",
                "mfit <- glmulti(form_glmulti, random=\"+(1|Speaker)+(1|Word)\", \n",
                "                data = mdat, method = \"h\", fitfunc = glmer.glmulti,  includeobjects = T,\n",
                "                crit = \"aic\", intercept = TRUE, marginality = FALSE, level = 2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After 50 models:\n",
                "Best model: Duration~1+Vowel+type+Gender+type:Vowel+Gender:Vowel\n",
                "Best model: Duration~1+Vowel+type+Gender+type:Vowel+Gender:Vowel+Gender:type\n",
                "Crit= 15875.9439868615\n",
                "Mean crit= 16152.5991758241\n",
                "\n",
                "After 100 models:\n",
                "Best model: Duration~1+Vowel+type+Gender+WordClass+Gender:Vowel\n",
                "Best model: Duration~1+Vowel+type+Gender+WordClass+Gender:Vowel+WordClass:Vowel\n",
                "Best model: Duration~1+Vowel+type+Gender+WordClass+Gender:Vowel+WordClass:type\n",
                "Best model: Duration~1+Vowel+type+Gender+WordClass+Gender:Vowel+WordClass:Vowel+WordClass:type\n",
                "Best model: Duration~1+Vowel+type+Gender+WordClass+Gender:Vowel+WordClass:Gender\n",
                "Best model: Duration~1+Vowel+type+Gender+WordClass+Gender:Vowel+WordClass:Vowel+WordClass:Gender\n",
                "Best model: Duration~1+Vowel+type+Gender+WordClass+Gender:Vowel+WordClass:type+WordClass:Gender\n",
                "Best model: Duration~1+Vowel+type+Gender+WordClass+Gender:Vowel+WordClass:Vowel+WordClass:type+WordClass:Gender\n",
                "Crit= 15869.1516948654\n",
                "Mean crit= 16099.4464548991\n",
                "Completed.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mb <- lmer(Duration ~ (1 | Word) + (1|Speaker) +\n",
                "             type + Vowel + Gender + WordClass + Gender:Vowel,\n",
                "           data = mdat)\n",
                "# inspect \n",
                "sjPlot::tab_model(ma, mb)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Visualize effects\n",
                " \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sjPlot::plot_model(mb, type = \"pred\", terms = c(\"Vowel\", \"type\")) +\n",
                "  scale_color_manual(values = c(\"lightgray\", \"orange\")) +\n",
                "  theme_bw() +\n",
                "  labs(title = \"\", y = \"Predicted duration\", x = \"Speaker type\")\n",
                "ggsave2(here::here(\"images\", \"lmer_type.png\"), width = 4, height = 3)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sjPlot::plot_model(mb, type = \"pred\", terms = c(\"Vowel\", \"Gender\")) +\n",
                "  theme_bw() +\n",
                "  labs(title = \"\", y = \"Predicted duration\")\n",
                "ggsave2(here::here(\"images\", \"lmer_vowelf2.png\"), width = 4, height = 3)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Overlap\n",
                "\n",
                "Check density\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wordplot3 <- function(fdat, vwl1, vwl2){\n",
                "  plt <- fdat %>% \n",
                "    dplyr::rename(label = Vowel)  %>%\n",
                "    dplyr::filter(label == vwl1 | label == vwl2) %>%\n",
                "    dplyr::group_by(Word, label) %>%\n",
                "    dplyr::mutate(meanF2 = mean(lobF2),\n",
                "                  meanF1 = mean(lobF1)) %>%\n",
                "    dplyr::ungroup() %>%\n",
                "    dplyr::group_by(label) %>%\n",
                "    dplyr::mutate(cF2 = mean(lobF2),\n",
                "                  cF1 = mean(lobF1)) %>%\n",
                "    # plot\n",
                "    ggplot(aes(x = lobF2, y = lobF1)) +\n",
                "  stat_density_2d(geom = \"polygon\",\n",
                "                  aes(alpha = ..level.., fill = label), bins = 8)  +\n",
                "    facet_grid( ~ type) +\n",
                "    scale_x_reverse(position = \"top\") + \n",
                "    scale_y_reverse(position = \"right\") + \n",
                "    #scale_fill_distiller(palette = \"Blues\", direction = 1) +\n",
                "    geom_text(aes(x = meanF2, y = meanF1, \n",
                "                  label = Word, color = label), size = 4) +\n",
                "    geom_text(aes(x = cF2, y = cF1, \n",
                "                  label = vowel), size = 6, color = \"gray20\") +\n",
                "    theme_minimal() +\n",
                "    theme(panel.grid.major = element_blank(), \n",
                "                  panel.grid.minor = element_blank(),\n",
                "                  legend.position = \"none\") +\n",
                "  scale_color_manual(values = c(\"orange3\", \"gray40\")) +\n",
                "  scale_fill_manual(values = c(\"orange\", \"gray\")) +\n",
                "    labs(x = \"Formant 2 (Lobanov normalized)\", y = \"Formant 1 (Lobanov normalized)\")\n",
                "  return(plt)\n",
                "  }\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pIi <- wordplot3(fdat = bdat, vwl1 = \"I\", vwl2 = \"i\")\n",
                "ggsave(here::here(\"images\", \"pIi.png\"), height = 3,  width = 5, dpi = 320)\n",
                "pIi\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wordplot3 <- function(fdat, vwl1, vwl2){\n",
                "  plt <- fdat %>% \n",
                "    dplyr::rename(label = Vowel)  %>%\n",
                "    dplyr::filter(label == vwl1 | label == vwl2) %>%\n",
                "    dplyr::group_by(Word, label) %>%\n",
                "    dplyr::mutate(meanF2 = mean(lobF2),\n",
                "                  meanF1 = mean(lobF1)) %>%\n",
                "    dplyr::ungroup() %>%\n",
                "    dplyr::group_by(label) %>%\n",
                "    dplyr::mutate(cF2 = mean(lobF2),\n",
                "                  cF1 = mean(lobF1)) %>%\n",
                "    # plot\n",
                "    ggplot(aes(x = lobF2, y = lobF1)) +\n",
                "  stat_density_2d(geom = \"polygon\",\n",
                "                  aes(alpha = ..level.., fill = label), bins = 8)  +\n",
                "    facet_grid( ~ type) +\n",
                "    scale_x_reverse(position = \"top\") + \n",
                "    scale_y_reverse(position = \"right\") + \n",
                "    #scale_fill_distiller(palette = \"Blues\", direction = 1) +\n",
                "    geom_text(aes(x = meanF2, y = meanF1, \n",
                "                  label = Word, color = label), size = 4) +\n",
                "    geom_text(aes(x = cF2, y = cF1, \n",
                "                  label = vowel), size = 6, color = \"gray20\") +\n",
                "    theme_minimal() +\n",
                "    theme(panel.grid.major = element_blank(), \n",
                "                  panel.grid.minor = element_blank(),\n",
                "                  legend.position = \"none\") +\n",
                "  scale_color_manual(values = c(\"red\", \"darkblue\")) +\n",
                "  scale_fill_manual(values = c(\"salmon\", \"lightblue\")) +\n",
                "    labs(x = \"Formant 2 (Lobanov normalized)\", y = \"Formant 1 (Lobanov normalized)\")\n",
                "  return(plt)\n",
                "  }\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pUu <- wordplot3(fdat = bdat, vwl1 = \"U\", vwl2 = \"u\")\n",
                "ggsave(here::here(\"images\", \"pUu.png\"), height = 3,  width = 5, dpi = 320)\n",
                "pUu\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wordplot3 <- function(fdat, vwl1, vwl2){\n",
                "  plt <- fdat %>% \n",
                "    dplyr::rename(label = Vowel)  %>%\n",
                "    dplyr::filter(label == vwl1 | label == vwl2) %>%\n",
                "    dplyr::group_by(Word, label) %>%\n",
                "    dplyr::mutate(meanF2 = mean(lobF2),\n",
                "                  meanF1 = mean(lobF1)) %>%\n",
                "    dplyr::ungroup() %>%\n",
                "    dplyr::group_by(label) %>%\n",
                "    dplyr::mutate(cF2 = mean(lobF2),\n",
                "                  cF1 = mean(lobF1)) %>%\n",
                "    # plot\n",
                "    ggplot(aes(x = lobF2, y = lobF1)) +\n",
                "  stat_density_2d(geom = \"polygon\",\n",
                "                  aes(alpha = ..level.., fill = label), bins = 8)  +\n",
                "    facet_grid( ~ type) +\n",
                "    scale_x_reverse(position = \"top\") + \n",
                "    scale_y_reverse(position = \"right\") + \n",
                "    #scale_fill_distiller(palette = \"Blues\", direction = 1) +\n",
                "    geom_text(aes(x = meanF2, y = meanF1, \n",
                "                  label = Word, color = label), size = 4) +\n",
                "    geom_text(aes(x = cF2, y = cF1, \n",
                "                  label = vowel), size = 6, color = \"gray20\") +\n",
                "    theme_minimal() +\n",
                "    theme(panel.grid.major = element_blank(), \n",
                "                  panel.grid.minor = element_blank(),\n",
                "                  legend.position = \"none\") +\n",
                "  scale_color_manual(values = c(\"green\", \"darkorchid4\")) +\n",
                "  scale_fill_manual(values = c(\"lightgreen\", \"darkorchid1\")) +\n",
                "    labs(x = \"Formant 2 (Lobanov normalized)\", y = \"Formant 1 (Lobanov normalized)\")\n",
                "  return(plt)\n",
                "  }\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pEe <- wordplot3(fdat = bdat, vwl1 = \"{\", vwl2 = \"E\")\n",
                "ggsave(here::here(\"images\", \"pEe.png\"), height = 3,  width = 5, dpi = 320)\n",
                "pEe\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bhattacharyya's affinity \n",
                "\n",
                "function for extracting Bhattacharyya's affinity by type and target variety\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "exba <- function(data, section, target, vwl1, vwl2){\n",
                "  ba <- data %>%\n",
                "  ungroup() %>%\n",
                "  dplyr::filter(type == section,\n",
                "                TargetVariety == target,\n",
                "                Vowel == vwl1 | Vowel == vwl2)\n",
                "\n",
                "  ba_formants <- ba %>%  dplyr::select(lobF1, lobF2)\n",
                "  # extract vowels\n",
                "  ba_vowel <- ba %>%  dplyr::select(vowel)\n",
                "  # spatial data frame\n",
                "  ba_spdf <- SpatialPointsDataFrame(ba_formants, ba_vowel)\n",
                "  # calculate Bhattacharyya's affinity\n",
                "  ba_ba <- kerneloverlap(ba_spdf, method = \"BA\")\n",
                "  # result\n",
                "  return(ba_ba[1,2])\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### I vs i: \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHN\n",
                "exba(data = bdat, section = \"CHN\", target = \"AmE\", vwl1 = \"I\", vwl2 = \"i\")\n",
                "# ENS\n",
                "exba(data = bdat, section = \"ENS\", target = \"AmE\", vwl1 = \"I\", vwl2 = \"i\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### U vs u:\n",
                "\n",
                "High-back \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHN\n",
                "exba(data = bdat, section = \"CHN\", target = \"AmE\", vwl1 = \"U\", vwl2 = \"u\")\n",
                "# ENS\n",
                "exba(data = bdat, section = \"ENS\", target = \"AmE\", vwl1 = \"U\", vwl2 = \"u\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### E vs {\n",
                "\n",
                "High-back \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CHN\n",
                "exba(data = bdat, section = \"CHN\", target = \"AmE\", vwl1 = \"{\", vwl2 = \"E\")\n",
                "# ENS\n",
                "exba(data = bdat, section = \"ENS\", target = \"AmE\", vwl1 = \"{\", vwl2 = \"E\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Tabulation  of the data\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tb1 <- bdat %>%\n",
                "  dplyr::filter(Vowel == \"{\"|Vowel == \"E\"|Vowel == \"i\"|Vowel == \"I\"|Vowel == \"u\"|Vowel == \"U\")  %>%\n",
                "  dplyr::mutate(Vowel = dplyr::case_when(Vowel == \"{\" ~ \"\\u00E6\",\n",
                "                                         Vowel == \"6\" ~ \"\\u0250\",\n",
                "                                         Vowel == \"e\" ~ \"\\u0065\",\n",
                "                                         Vowel == \"E\" ~ \"\\u025B\",\n",
                "                                         Vowel == \"i\" ~ \"\\u0069\",\n",
                "                                         Vowel == \"I\" ~ \"\\u026A\",\n",
                "                                         Vowel == \"Q\" ~ \"\\u0252\",\n",
                "                                         Vowel == \"u\" ~ \"\\u0075\",\n",
                "                                         Vowel == \"U\" ~ \"\\u028A\",\n",
                "                                         Vowel == \"V\" ~ \"\\u028C\",\n",
                "                                         TRUE ~ Vowel))  %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::group_by(type) %>%\n",
                "  dplyr::mutate(speakers = length(table(Speaker))) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::group_by(type, Vowel) %>%\n",
                "  dplyr::summarise(speakers = speakers,\n",
                "                   obs = n()) %>%\n",
                "  unique() %>%\n",
                "  tidyr::spread(Vowel, obs) %>%\n",
                "  dplyr::ungroup()  %>%\n",
                "  adorn_totals(\"row\")%>%\n",
                "  adorn_totals(\"col\") %>%\n",
                "  dplyr::mutate(Total = Total-speakers)\n",
                "# save\n",
                "write.table(tb1, here::here(\"tables\", \"tb1_icame.txt\"), sep = \"\\t\")\n",
                "# inspect\n",
                "tb1\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "tabulate proficiency\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tb3 <- bdat %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::filter(type == \"CHN\")%>%\n",
                "  dplyr::group_by(Proficiency, Gender) %>%\n",
                "  dplyr::summarise(speakers = length(table(Speaker))) %>%\n",
                "  tidyr::spread(Proficiency, speakers) %>%\n",
                "  dplyr::ungroup()  %>%\n",
                "  adorn_totals(\"row\")%>%\n",
                "  adorn_totals(\"col\")\n",
                "# save\n",
                "write.table(tb3, here::here(\"tables\", \"tb3_icame.txt\"), sep = \"\\t\")\n",
                "# inspect\n",
                "tb3\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary(bdat)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "summary(mdat)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Outro\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save tables\n",
                "base::saveRDS(mdat, file = here::here(\"tables\", \"mdat.rda\"))\n",
                "base::saveRDS(bdat, file = here::here(\"tables\", \"bdat.rda\"))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Citation & Session Info\n",
                "\n",
                "Schweinberger, Martin and Ruihua Yin. 2023. A Corpus-Based Acoustic Analysis of Monophthongal Vowels among Chinese Learners and Native Speakers of English. Brisbane: The University of Queensland, School of Languages and Cultures. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sessionInfo()\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
